# -*- coding: utf-8 -*-

"""
ãƒ–ãƒ­ã‚°ã®æ›´æ–°ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€æ–°ã—ã„è¨˜äº‹ãŒã‚ã‚Œã°Gmailã§é€šçŸ¥ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€ä»¥ä¸‹ã®å‡¦ç†ã‚’è¡Œã„ã¾ã™:
1. æŒ‡å®šã•ã‚ŒãŸãƒ–ãƒ­ã‚°URLã‹ã‚‰HTMLã‚’å–å¾—ã—ã¾ã™ã€‚
2. HTMLã‚’è§£æã—ã€æœ€æ–°è¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«ã€URLã€ã‚µãƒ ãƒã‚¤ãƒ«ç”»åƒã‚’å–å¾—ã—ã¾ã™ã€‚
   - beautifulsoup4ãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯ãã‚Œã‚’ä½¿ç”¨ã—ã€ãªã‘ã‚Œã°æ­£è¦è¡¨ç¾ã§ã®è§£æã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™ã€‚
3. å‰å›å–å¾—ã—ãŸè¨˜äº‹ã®URLã¨æ¯”è¼ƒã—ã€æ›´æ–°ãŒã‚ã‚‹ã‹ã‚’ç¢ºèªã—ã¾ã™ã€‚
4. æ›´æ–°ãŒã‚ã£ãŸå ´åˆã€ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã—ãŸGmailã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±ã‚’ä½¿ã£ã¦é€šçŸ¥ãƒ¡ãƒ¼ãƒ«ã‚’é€ä¿¡ã—ã¾ã™ã€‚
5. æœ€æ–°ã®è¨˜äº‹URLã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã€æ¬¡å›ã®å®Ÿè¡Œã«å‚™ãˆã¾ã™ã€‚
"""

import urllib.request
import urllib.error
import os
import re
import smtplib
import json
from datetime import datetime
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

# --- ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®š ---
LAST_ARTICLE_FILE = 'last_article.txt'  # å‰å›è¨˜äº‹ã®URLã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«
BLOG_URL = 'https://www.t-p-o.com/blog/'  # ãƒã‚§ãƒƒã‚¯å¯¾è±¡ã®ãƒ–ãƒ­ã‚°URL

# URè³ƒè²¸ç‰©ä»¶è¨­å®š
UR_STATE_FILE = 'ur_properties.json'  # URç‰©ä»¶ã®çŠ¶æ…‹ã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«
TARGET_UR_PROPERTIES = {
    '20_1830': {'ward': 'å“å·åŒº', 'name': 'å¤§äº•å…­ä¸ç›®'},
    '20_3550': {'ward': 'å“å·åŒº', 'name': 'å“å·å…«æ½®ãƒ‘ãƒ¼ã‚¯ã‚¿ã‚¦ãƒ³ æ½®è·¯åŒ—ç¬¬äºŒãƒã‚¤ãƒ„'},
    '20_3640': {'ward': 'å“å·åŒº', 'name': 'å“å·å…«æ½®ãƒ‘ãƒ¼ã‚¯ã‚¿ã‚¦ãƒ³ æ½®è·¯å—ç¬¬ä¸€ãƒã‚¤ãƒ„'},
    '20_3810': {'ward': 'å“å·åŒº', 'name': 'å“å·å…«æ½®ãƒ‘ãƒ¼ã‚¯ã‚¿ã‚¦ãƒ³ æ½®è·¯ä¸­å¤®ãƒã‚¤ãƒ„'},
    '20_7220': {'ward': 'å“å·åŒº', 'name': 'ã‚³ãƒ³ãƒ•ã‚©ãƒ¼ãƒ«å“å·è¥¿å¤§äº•'},
    '20_4920': {'ward': 'æ¸¯åŒº', 'name': 'ãƒ‡ãƒ¥ãƒ—ãƒ¬èŠæµ¦'},
    '20_5180': {'ward': 'ç›®é»’åŒº', 'name': 'æµæ¯”å¯¿ãƒ“ãƒ¥ãƒ¼ã‚¿ãƒ¯ãƒ¼'},
    '20_6480': {'ward': 'ç›®é»’åŒº', 'name': 'ä¸­ç›®é»’ã‚²ãƒ¼ãƒˆã‚¿ã‚¦ãƒ³ãƒã‚¤ãƒ„'},
    '20_7090': {'ward': 'ç›®é»’åŒº', 'name': 'ä¸­ç›®é»’ã‚¢ãƒˆãƒ©ã‚¹ã‚¿ãƒ¯ãƒ¼'},
}

# --- ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
# beautifulsoup4ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªãã¦ã‚‚å‹•ä½œã™ã‚‹ã‚ˆã†ã«ã€ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦ã¿ã‚‹
try:
    from bs4 import BeautifulSoup
except ImportError:
    BeautifulSoup = None

# Seleniumã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from selenium import webdriver
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.chrome.service import Service
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from webdriver_manager.chrome import ChromeDriverManager
    SELENIUM_AVAILABLE = True
except ImportError:
    SELENIUM_AVAILABLE = False
    print("Warning: Selenium not available. UR vacancy checking will be disabled.")

# --- é–¢æ•°å®šç¾© ---

def read_last_article_url():
    """
    last_article.txt ã‹ã‚‰å‰å›ã®è¨˜äº‹URLã‚’èª­ã¿è¾¼ã‚€ã€‚
    ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯Noneã‚’è¿”ã™ã€‚
    """
    if not os.path.exists(LAST_ARTICLE_FILE):
        return None
    with open(LAST_ARTICLE_FILE, 'r', encoding='utf-8') as f:
        return f.read().strip()

def write_last_article_url(url):
    """
    last_article.txt ã«æ–°ã—ã„URLã‚’æ›¸ãè¾¼ã‚€ã€‚
    """
    with open(LAST_ARTICLE_FILE, 'w', encoding='utf-8') as f:
        f.write(url)

def fetch_blog_html(url):
    """
    æŒ‡å®šã•ã‚ŒãŸURLã®HTMLã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—ã™ã‚‹ã€‚
    æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª urllib ã‚’ä½¿ç”¨ã€‚
    """
    try:
        with urllib.request.urlopen(url) as response:
            if response.getcode() == 200:
                return response.read().decode('utf-8')
            else:
                print(f"Error fetching blog HTML: Status code {response.getcode()}")
                return None
    except urllib.error.URLError as e:
        print(f"Error fetching blog HTML: {e}")
        return None

# --- HTMLè§£æé–¢æ•° ---

def parse_latest_article_with_bs(html):
    """
    BeautifulSoupã‚’ä½¿ã£ã¦HTMLã‚’è§£æã—ã€æœ€æ–°è¨˜äº‹ã®æƒ…å ±ã‚’æŠ½å‡ºã™ã‚‹ã€‚
    (æ³¨: ç¾åœ¨ã®å®Ÿè¡Œç’°å¢ƒã§ã¯beautifulsoup4ãŒä½¿ãˆãªã„ãŸã‚ã€ã“ã®é–¢æ•°ã¯å‘¼ã³å‡ºã•ã‚Œãªã„)
    """
    soup = BeautifulSoup(html, 'html.parser')
    # ã‚»ãƒ¬ã‚¯ã‚¿ã¯ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚µã‚¤ãƒˆã®æ§‹é€ ã«åˆã‚ã›ã¦èª¿æ•´ãŒå¿…è¦
    latest_article_element = soup.select_one('li[id^="post-"]')

    if not latest_article_element:
        return None

    title_element = latest_article_element.select_one('h2')
    url_element = latest_article_element.select_one('.blog-more a')
    thumbnail_element = latest_article_element.select_one('figure.thumb img')

    title = title_element.get_text(strip=True) if title_element else 'No Title'
    url = url_element['href'] if url_element and 'href' in url_element.attrs else 'No URL'
    thumbnail_url = thumbnail_element['src'] if thumbnail_element and 'src' in thumbnail_element.attrs else 'No Thumbnail'

    # URLãŒç›¸å¯¾ãƒ‘ã‚¹ã®å ´åˆã€çµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›
    if url.startswith('/'):
        url = "https://www.t-p-o.com" + url

    return {
        'title': title,
        'url': url,
        'thumbnail_url': thumbnail_url
    }

def parse_latest_article_with_regex(html):
    """
    æ­£è¦è¡¨ç¾ã‚’ä½¿ã£ã¦HTMLã‚’è§£æã—ã€æœ€æ–°è¨˜äº‹ã®æƒ…å ±ã‚’æŠ½å‡ºã™ã‚‹ã€‚
    HTMLæ§‹é€ ã®å¤‰æ›´ã«å¼±ã„ãŸã‚ã€ã‚ãã¾ã§BeautifulSoupãŒä½¿ãˆãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚
    """
    # æœ€æ–°ã®è¨˜äº‹ã‚’å«ã‚€å¯èƒ½æ€§ãŒæœ€ã‚‚é«˜ã„ã€æœ€åˆã®<li>ãƒ–ãƒ­ãƒƒã‚¯ã‚’ç‰¹å®š
    item_match = re.search(r'<li id="post-.*?">.*?</li>', html, re.DOTALL)
    if not item_match:
        print("Regex Error: Could not find the latest article block (li id='post-...').")
        return None
    
    item_html = item_match.group(0)

    # ãƒ–ãƒ­ãƒƒã‚¯å†…ã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«ã‚’æŠ½å‡º
    title_match = re.search(r'<h2>(.*?)</h2>', item_html, re.DOTALL)
    title = title_match.group(1).strip() if title_match else 'No Title'

    # ãƒ–ãƒ­ãƒƒã‚¯å†…ã‹ã‚‰è¨˜äº‹URLã‚’æŠ½å‡º
    url_match = re.search(r'<div class="blog-more"><a href="(.*?)">MORE</a></div>', item_html, re.DOTALL)
    if url_match:
        relative_url = url_match.group(1)
        # URLãŒç›¸å¯¾ãƒ‘ã‚¹ã®å ´åˆã€çµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›
        if relative_url.startswith('/'):
            url = "https://www.t-p-o.com" + relative_url
        else:
            url = relative_url
    else:
        url = 'No URL'

    # ãƒ–ãƒ­ãƒƒã‚¯å†…ã‹ã‚‰ã‚µãƒ ãƒã‚¤ãƒ«URLã‚’æŠ½å‡º
    thumb_match = re.search(r'<figure class="thumb">.*?<img.*?src="(.*?)".*?>.*?</figure>', item_html, re.DOTALL)
    thumbnail_url = thumb_match.group(1) if thumb_match else 'No Thumbnail'

    if title == 'No Title' or url == 'No URL':
        print(f"Regex Error: Could not parse title or URL. Title Match: {title_match}, URL Match: {url_match}")
        return None

    return {
        'title': title,
        'url': url,
        'thumbnail_url': thumbnail_url
    }

def parse_latest_article(html):
    """
    HTMLã‚’è§£æã—ã€æœ€æ–°è¨˜äº‹ã®æƒ…å ±ã‚’æŠ½å‡ºã™ã‚‹ã€‚
    BeautifulSoupãŒåˆ©ç”¨å¯èƒ½ã§ã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨ã—ã€ãªã‘ã‚Œã°æ­£è¦è¡¨ç¾ã§ã®è§£æã‚’è©¦ã¿ã‚‹ã€‚
    """
    if not html:
        return None

    if BeautifulSoup:
        print("Parsing with BeautifulSoup...")
        return parse_latest_article_with_bs(html)
    else:
        # GitHub Actionsç’°å¢ƒã§ã¯ã€pipã§ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã‚‹æƒ³å®š
        # ãƒ­ãƒ¼ã‚«ãƒ«ã®CLIç’°å¢ƒã§ã¯ã“ã¡ã‚‰ãŒå®Ÿè¡Œã•ã‚Œã‚‹
        print("BeautifulSoup not found. Parsing with Regex (might be unstable)...")
        return parse_latest_article_with_regex(html)

# --- ãƒ¡ãƒ¼ãƒ«é€ä¿¡ç”¨é–¢æ•° ---

def get_email_credentials():
    """
    ç’°å¢ƒå¤‰æ•°ã‹ã‚‰Gmailã®èªè¨¼æƒ…å ±ã‚’èª­ã¿è¾¼ã‚€ã€‚
    GitHub Actionsã®Secretsã«è¨­å®šã™ã‚‹ã“ã¨ã‚’æƒ³å®šã€‚
    """
    gmail_address = os.getenv('GMAIL_ADDRESS')
    gmail_app_password = os.getenv('GMAIL_APP_PASSWORD')
    recipient_email = os.getenv('RECIPIENT_EMAIL')

    if not all([gmail_address, gmail_app_password, recipient_email]):
        print("Warning: Email credentials (GMAIL_ADDRESS, GMAIL_APP_PASSWORD, RECIPIENT_EMAIL) are not set.")
        return None, None, None

    return gmail_address, gmail_app_password, recipient_email

def create_email_body(article, recipient_email, sender_email):
    """
    HTMLå½¢å¼ã®ãƒ¡ãƒ¼ãƒ«æœ¬æ–‡ã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    subject = f"ãƒ–ãƒ­ã‚°æ›´æ–°é€šçŸ¥: {article['title']}"
    
    msg = MIMEMultipart()
    msg['Subject'] = subject
    msg['To'] = recipient_email
    msg['From'] = sender_email

    html_body = f"""
    <html>
    <body>
        <h2>æ–°ã—ã„è¨˜äº‹ãŒæŠ•ç¨¿ã•ã‚Œã¾ã—ãŸï¼</h2>
        <h3>{article['title']}</h3>
        <p><a href="{article['url']}">è¨˜äº‹ã‚’èª­ã‚€</a></p>
        <p><img src="{article['thumbnail_url']}" alt="Thumbnail" width="300"></p>
    </body>
    </html>
    """
    
    msg.attach(MIMEText(html_body, 'html', 'utf-8'))
    return msg

def send_email(message, sender_email, sender_password):
    """
    Gmailã®SMTPã‚µãƒ¼ãƒãƒ¼çµŒç”±ã§ãƒ¡ãƒ¼ãƒ«ã‚’é€ä¿¡ã™ã‚‹ã€‚
    """
    try:
        with smtplib.SMTP_SSL('smtp.gmail.com', 465) as smtp:
            smtp.login(sender_email, sender_password)
            smtp.send_message(message)
            print("Email sent successfully!")
    except smtplib.SMTPException as e:
        print(f"Error sending email: {e}")
    except Exception as e:
        print(f"An unexpected error occurred while sending email: {e}")

# --- URç‰©ä»¶çŠ¶æ…‹ç®¡ç†é–¢æ•° ---

def read_ur_state():
    """
    ur_properties.json ã‹ã‚‰å‰å›ã®URç‰©ä»¶çŠ¶æ…‹ã‚’èª­ã¿è¾¼ã‚€ã€‚
    ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ç©ºã®æ§‹é€ ã‚’è¿”ã™ã€‚
    """
    if not os.path.exists(UR_STATE_FILE):
        return {'last_updated': None, 'properties': {}}

    try:
        with open(UR_STATE_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except (json.JSONDecodeError, IOError) as e:
        print(f"Error reading UR state file: {e}")
        return {'last_updated': None, 'properties': {}}

def write_ur_state(state):
    """
    ur_properties.json ã«æ–°ã—ã„çŠ¶æ…‹ã‚’æ›¸ãè¾¼ã‚€ã€‚
    """
    try:
        with open(UR_STATE_FILE, 'w', encoding='utf-8') as f:
            json.dump(state, f, ensure_ascii=False, indent=2)
    except IOError as e:
        print(f"Error writing UR state file: {e}")

# --- URç‰©ä»¶ç©ºå®¤å–å¾—é–¢æ•°ï¼ˆSeleniumä½¿ç”¨ï¼‰ ---

def setup_driver():
    """
    Seleniumã®headless Chromeãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã™ã‚‹ã€‚
    """
    if not SELENIUM_AVAILABLE:
        raise ImportError("Selenium is not available")

    options = Options()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-gpu')
    options.add_argument('--window-size=1920,1080')
    # User-Agentã‚’è¨­å®šã—ã¦ãƒ–ãƒ©ã‚¦ã‚¶ã¨ã—ã¦èªè­˜ã•ã›ã‚‹
    options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')

    try:
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)
        driver.set_page_load_timeout(30)
        return driver
    except Exception as e:
        print(f"Error setting up Chrome driver: {e}")
        # GitHub Actionsã®ç’°å¢ƒã§ã¯chromium-chromedriverã‚’ä½¿ç”¨
        try:
            options.binary_location = '/usr/bin/chromium-browser'
            service = Service('/usr/bin/chromedriver')
            driver = webdriver.Chrome(service=service, options=options)
            driver.set_page_load_timeout(30)
            return driver
        except Exception as e2:
            print(f"Error with fallback driver: {e2}")
            raise

def fetch_vacancy_count(property_id):
    """
    æŒ‡å®šã•ã‚ŒãŸURç‰©ä»¶IDã®ç©ºå®¤æ•°ã‚’å–å¾—ã™ã‚‹ã€‚
    Seleniumã‚’ä½¿ã£ã¦ãƒšãƒ¼ã‚¸ã‚’èª­ã¿è¾¼ã¿ã€ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°å¾Œã®HTMLã‹ã‚‰ç©ºå®¤æ•°ã‚’æŠ½å‡ºã™ã‚‹ã€‚
    """
    if not SELENIUM_AVAILABLE:
        print("Selenium not available, skipping vacancy fetch")
        return 0

    driver = None
    try:
        driver = setup_driver()
        url = f"https://www.ur-net.go.jp/chintai/kanto/tokyo/{property_id}.html"
        print(f"  Fetching: {url}")

        driver.get(url)

        # JavaScriptã®ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã‚’å¾…ã¤
        import time
        time.sleep(3)

        # ç©ºå®¤ãŒãªã„å ´åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç¢ºèª
        try:
            no_vacancy_element = driver.find_element(By.XPATH, "//*[contains(text(), 'å½“ã‚µã‚¤ãƒˆã‹ã‚‰ã™ãã«ã”æ¡ˆå†…ã§ãã‚‹ãŠéƒ¨å±‹ãŒã”ã–ã„ã¾ã›ã‚“')]")
            if no_vacancy_element:
                print(f"    No vacancies available (message found)")
                return 0
        except:
            pass

        # ç©ºå®¤ãƒ†ãƒ¼ãƒ–ãƒ«ã®è¡Œæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        # é€šå¸¸ã€ç©ºå®¤ãŒã‚ã‚‹å ´åˆã¯ã€ŒãŠéƒ¨å±‹æƒ…å ±ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã«è¡ŒãŒè¡¨ç¤ºã•ã‚Œã‚‹
        try:
            # ãƒ†ãƒ¼ãƒ–ãƒ«ã®è¡Œã‚’æ¢ã™ï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’é™¤ãï¼‰
            vacancy_rows = driver.find_elements(By.CSS_SELECTOR, "table.bukken_table tbody tr")
            # ãƒ‡ãƒ¼ã‚¿è¡Œã®ã¿ã‚«ã‚¦ãƒ³ãƒˆï¼ˆã‚¯ãƒ©ã‚¹åã‚„å†…å®¹ã§çµã‚Šè¾¼ã¿ï¼‰
            vacancy_count = 0
            for row in vacancy_rows:
                # è¡Œã«ãƒªãƒ³ã‚¯ã‚„ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿ã‚«ã‚¦ãƒ³ãƒˆ
                if row.find_elements(By.TAG_NAME, "a") or row.find_elements(By.CLASS_NAME, "price"):
                    vacancy_count += 1

            print(f"    Vacancy count: {vacancy_count}")
            return vacancy_count
        except Exception as e:
            print(f"    Error parsing vacancy table: {e}")

            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šã€Œâ—‹ä»¶ã€ã®ã‚ˆã†ãªè¡¨ç¤ºã‚’æ¢ã™
            try:
                page_text = driver.page_source
                # "ç©ºå®¤" ã‚„ "å‹Ÿé›†ä¸­" ãªã©ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨æ•°å­—ã‚’æ¢ã™
                import re
                match = re.search(r'(\d+)\s*ä»¶', page_text)
                if match:
                    count = int(match.group(1))
                    print(f"    Found vacancy count via text pattern: {count}")
                    return count
            except Exception as e2:
                print(f"    Fallback parsing also failed: {e2}")

            return 0

    except Exception as e:
        print(f"  Error fetching vacancy for {property_id}: {e}")
        return 0
    finally:
        if driver:
            driver.quit()

def detect_vacancy_increases(old_state, new_state):
    """
    å‰å›ã®çŠ¶æ…‹ã¨ç¾åœ¨ã®çŠ¶æ…‹ã‚’æ¯”è¼ƒã—ã€ç©ºå®¤ãŒå¢—ãˆãŸç‰©ä»¶ã®ãƒªã‚¹ãƒˆã‚’è¿”ã™ã€‚
    """
    increases = []

    for prop_id in TARGET_UR_PROPERTIES:
        old_count = old_state.get(prop_id, {}).get('vacancy_count', 0)
        new_count = new_state.get(prop_id, {}).get('vacancy_count', 0)

        if new_count > old_count:
            increases.append({
                'property_id': prop_id,
                'old_count': old_count,
                'new_count': new_count,
                'name': new_state[prop_id]['name'],
                'ward': new_state[prop_id]['ward'],
                'url': new_state[prop_id]['url']
            })

    return increases

def create_ur_email_body(increases, recipient_email, sender_email):
    """
    URç©ºå®¤å¢—åŠ é€šçŸ¥ã®HTMLå½¢å¼ã®ãƒ¡ãƒ¼ãƒ«æœ¬æ–‡ã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    subject = f"URç©ºå®¤æƒ…å ±æ›´æ–°: {len(increases)}ä»¶ã®ç‰©ä»¶ã«ç©ºããŒå¢—ãˆã¾ã—ãŸ"

    msg = MIMEMultipart()
    msg['Subject'] = subject
    msg['To'] = recipient_email
    msg['From'] = sender_email

    html_body = """
    <html>
    <body>
        <h2>ğŸ  URç©ºå®¤æƒ…å ±æ›´æ–°é€šçŸ¥</h2>
        <h3>ç©ºå®¤ãŒå¢—ãˆãŸç‰©ä»¶</h3>
        <ul>
    """

    for item in increases:
        html_body += f"""
            <li>
                <strong>{item['name']}</strong> ({item['ward']})<br>
                ç©ºå®¤æ•°: {item['old_count']}å®¤ â†’ {item['new_count']}å®¤<br>
                <a href="{item['url']}">è©³ç´°ã‚’è¦‹ã‚‹</a>
            </li>
        """

    html_body += """
        </ul>
        <p style="margin-top: 30px; color: #666; font-size: 12px;">
            ã“ã®ãƒ¡ãƒ¼ãƒ«ã¯è‡ªå‹•é€ä¿¡ã•ã‚Œã¦ã„ã¾ã™ã€‚<br>
            å¯¾è±¡ã‚¨ãƒªã‚¢: å“å·åŒºã€æ¸¯åŒºã€ç›®é»’åŒº
        </p>
    </body>
    </html>
    """

    msg.attach(MIMEText(html_body, 'html', 'utf-8'))
    return msg

def check_ur_vacancies():
    """
    URç‰©ä»¶ã®ç©ºå®¤çŠ¶æ³ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€ç©ºå®¤ãŒå¢—ãˆãŸå ´åˆã¯é€šçŸ¥ã™ã‚‹ã€‚
    """
    if not SELENIUM_AVAILABLE:
        print("Selenium not available, skipping UR vacancy check")
        return

    print("--- UR Vacancy Check Start ---")

    # å‰å›ã®çŠ¶æ…‹ã‚’èª­ã¿è¾¼ã‚€
    old_state = read_ur_state()
    print(f"Loaded previous state for {len(old_state.get('properties', {}))} properties")

    # ç¾åœ¨ã®ç©ºå®¤ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    new_state = {
        'last_updated': datetime.now().isoformat(),
        'properties': {}
    }

    for prop_id, info in TARGET_UR_PROPERTIES.items():
        print(f"Checking property: {info['name']} ({prop_id})")
        try:
            vacancy_count = fetch_vacancy_count(prop_id)
            new_state['properties'][prop_id] = {
                'name': info['name'],
                'ward': info['ward'],
                'vacancy_count': vacancy_count,
                'url': f"https://www.ur-net.go.jp/chintai/kanto/tokyo/{prop_id}.html",
                'last_changed': datetime.now().isoformat()
            }
        except Exception as e:
            print(f"Error fetching {prop_id}: {e}")
            # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã€å¤ã„ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨
            if prop_id in old_state.get('properties', {}):
                print(f"  Using old data for {prop_id}")
                new_state['properties'][prop_id] = old_state['properties'][prop_id]
            else:
                # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯0ã¨ã—ã¦è¨˜éŒ²
                new_state['properties'][prop_id] = {
                    'name': info['name'],
                    'ward': info['ward'],
                    'vacancy_count': 0,
                    'url': f"https://www.ur-net.go.jp/chintai/kanto/tokyo/{prop_id}.html",
                    'last_changed': datetime.now().isoformat()
                }

    # ç©ºå®¤ã®å¢—åŠ ã‚’æ¤œå‡º
    increases = detect_vacancy_increases(
        old_state.get('properties', {}),
        new_state['properties']
    )

    # å¢—åŠ ãŒã‚ã£ãŸå ´åˆã¯é€šçŸ¥ã‚’é€ä¿¡
    if increases:
        print(f"Found {len(increases)} properties with increased vacancies:")
        for item in increases:
            print(f"  - {item['name']}: {item['old_count']} â†’ {item['new_count']}")

        # ãƒ¡ãƒ¼ãƒ«é€ä¿¡
        gmail_address, gmail_app_password, recipient_email = get_email_credentials()
        if gmail_address:
            print("Sending UR vacancy notification email...")
            email_msg = create_ur_email_body(increases, recipient_email, gmail_address)
            send_email(email_msg, gmail_address, gmail_app_password)
        else:
            print("Skipping email notification because credentials are not set.")
    else:
        print("No vacancy increases detected")

    # çŠ¶æ…‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°ï¼ˆå¤‰æ›´ãŒãªãã¦ã‚‚æœ€æ–°ã®çŠ¶æ…‹ã‚’ä¿å­˜ï¼‰
    print(f"Updating UR state file...")
    write_ur_state(new_state)

    print("--- UR Vacancy Check End ---")

# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---

def check_blog_updates():
    """
    ãƒ–ãƒ­ã‚°ã®æ›´æ–°ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€æ–°ã—ã„è¨˜äº‹ãŒã‚ã‚Œã°é€šçŸ¥ã™ã‚‹ã€‚
    """
    print("--- Blog Update Check Start ---")

    # 1. æœ€æ–°è¨˜äº‹ã®æƒ…å ±ã‚’å–å¾—
    print(f"Fetching latest article from {BLOG_URL}...")
    html = fetch_blog_html(BLOG_URL)
    if not html:
        print("Error: Could not fetch blog page.")
        return

    latest_article = parse_latest_article(html)
    if not latest_article or latest_article.get('url') == 'No URL':
        print("Error: Could not parse the latest article.")
        return

    print("Successfully fetched and parsed the latest article.")
    print(f"  - Title: {latest_article['title']}")
    print(f"  - URL: {latest_article['url']}")

    # 2. å‰å›ã®è¨˜äº‹URLã¨æ¯”è¼ƒ
    last_url = read_last_article_url()
    print(f"Last article URL was: {last_url}")

    if latest_article['url'] == last_url:
        print("No new articles found.")
    else:
        print("Found a new article!")

        # 3. ãƒ¡ãƒ¼ãƒ«é€ä¿¡å‡¦ç†
        gmail_address, gmail_app_password, recipient_email = get_email_credentials()
        if gmail_address:
            print("Creating and sending blog update email...")
            email_msg = create_email_body(latest_article, recipient_email, gmail_address)
            send_email(email_msg, gmail_address, gmail_app_password)
        else:
            print("Skipping email notification because credentials are not set.")

        # 4. æœ€å¾Œã«èª­ã¿è¾¼ã‚“ã è¨˜äº‹ã®URLã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        print(f"Updating last article URL to: {latest_article['url']}")
        write_last_article_url(latest_article['url'])

    print("--- Blog Update Check End ---")

def main():
    """
    ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ•ãƒ­ãƒ¼
    ãƒ–ãƒ­ã‚°æ›´æ–°ã¨URç©ºå®¤çŠ¶æ³ã®ä¸¡æ–¹ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã€‚
    """
    print("=== Notification Script Start ===")
    print()

    # ãƒ–ãƒ­ã‚°æ›´æ–°ãƒã‚§ãƒƒã‚¯
    check_blog_updates()
    print()

    # URç©ºå®¤ãƒã‚§ãƒƒã‚¯
    check_ur_vacancies()
    print()

    print("=== Notification Script End ===")

if __name__ == '__main__':
    main()
